{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c763e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Define the blob storage path to the cleaned CSV file\n",
    "csv_path = \"https://mehaktrafficstore.blob.core.windows.net/traffic-data/berlin_traffic.csv?sp=r&st=2025-07-25T14:00:14Z&se=2025-08-30T22:15:14Z&spr=https&sv=2024-11-04&sr=b&sig=xxeptAHsjXm6U4rb2Rl0GX%2BPr1vhWCkedeEcNaSzJ70%3D\"\n",
    "\n",
    "# Step 3: Read the CSV into Pandas DataFrame\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    sep=',',\n",
    "    encoding='ISO-8859-1',\n",
    "    quotechar='\"',\n",
    "    error_bad_lines=False,   # Skip problematic lines\n",
    "    warn_bad_lines=True,     # Warn which lines are skipped\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "\n",
    "# Step 4: Clean column names and remove empty rows\n",
    "df = df.dropna(how='all')\n",
    "df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "\n",
    "# Step 5: Attempt to convert datetime columns\n",
    "for col in df.columns:\n",
    "    if \"time\" in col or \"datum\" in col:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Step 6: Drop rows with invalid datetime if any\n",
    "datetime_cols = [col for col in df.columns if pd.api.types.is_datetime64_any_dtype(df[col])]\n",
    "if datetime_cols:\n",
    "    df = df.dropna(subset=[datetime_cols[0]])\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Step 7: Convert Pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "# Step 8: Write the Spark DataFrame to DBFS\n",
    "output_path = \"dbfs:/user/mehak/processed/berlin_clean.csv\"\n",
    "spark_df.write.mode(\"overwrite\").option(\"header\", True).csv(output_path)\n",
    "\n",
    "# Step 9: Verify file is written\n",
    "display(dbutils.fs.ls(\"dbfs:/user/mehak/processed/\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
